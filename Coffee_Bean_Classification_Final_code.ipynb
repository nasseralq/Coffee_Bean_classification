{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0696483",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f896cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import mean\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import datetime\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('arabica_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6092f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('merged_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df, df1]\n",
    "\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de442ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05111f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['Lot.Number','Unnamed: 0','In.Country.Partner'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Company'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e35873",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Company'].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Country.of.Origin'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe256090",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result['Country.of.Origin'].notna()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['Farm.Name','Mill','ICO.Number','Company','Altitude','Producer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0297fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b171cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= result.drop(['Number.of.Bags','Bag.Weight'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result[\"Harvest.Year\"] == \"2017 / 2018\", \"Harvest.Year\"] = \"2018\"\n",
    "result.loc[result[\"Harvest.Year\"] == \"2016 / 2017\", \"Harvest.Year\"] = \"2017\"\n",
    "result.loc[result[\"Harvest.Year\"] == \"2015/2016\", \"Harvest.Year\"] = \"2016\"\n",
    "result.loc[result[\"Harvest.Year\"] == \"2014/2015\", \"Harvest.Year\"] = \"2015\"\n",
    "result.loc[result[\"Harvest.Year\"] == \"2013/2014\", \"Harvest.Year\"] = \"2014\"\n",
    "result.loc[result[\"Harvest.Year\"] == \"2011/2012\", \"Harvest.Year\"] = \"2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result['Harvest.Year'].notna()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['Variety'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923c50d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas and pandas profiling\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "# Importing the dataset\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title='Titanic Report')\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ee36b",
   "metadata": {},
   "source": [
    "If the altitude increases, acidity will decrease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.altitude_mean_meters.plot(kind = \"line\", color = \"Blue\", label = \"altitude_mean_meters\", linewidth = 1, alpha = 0.5, grid = True , linestyle = \":\")\n",
    "result.Acidity.plot(color = \"red\", label = \"Acidity\", linewidth = 1, alpha = 0.5, grid = True , linestyle = \"-.\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.xlabel(\"x axis\")\n",
    "plt.ylabel(\"y axis\")\n",
    "plt.title(\"Line plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6a18f",
   "metadata": {},
   "source": [
    "Top coffee producing countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ed56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = result.groupby(\"Country.of.Origin\").size().reset_index(name=\"Harvest.Year\") \\\n",
    "    .sort_values(\"Harvest.Year\", ascending=False).head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ch_ = sns.barplot(x=\"Harvest.Year\", y=\"Country.of.Origin\", data=cdf,palette=('mako'), ax=ax)\n",
    "ch_ = ax.set(xlabel=\"Production\", ylabel=\"Country of Origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf64e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby(['Country.of.Origin','Harvest.Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Country.of.Origin'].value_counts().plot(kind='bar', title= 'Distribution of coffee' ,  rot=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed527c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc3103f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68535fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Total.Cup.Points'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d204423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grading_coffee(x):\n",
    "\n",
    "    if x>=80:\n",
    "        return 'speciality'\n",
    "    elif x>=70:\n",
    "        return 'commercial+'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=result.rename(columns={'Total.Cup.Points':'Total_Cup_Points'}, inplace=True)\n",
    "#result.columns[18] = \"Total_Cup_Points\"\n",
    "result1 = result.rename(columns={'Total.Cup.Points': 'Total_Cup_Points'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['coffee_grade']=result1.Total_Cup_Points.apply(grading_coffee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.groupby(['coffee_grade','Total_Cup_Points'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901eabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['coffee_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1['coffee_grade'].value_counts().plot(kind='bar', title= 'Distribution coffee grade' ,  rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f92755",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca279b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(result1, test_size=.2, random_state=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d042818",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:,['Aroma', 'Flavor', 'Aftertaste','Acidity'\n",
    "                          ,'Body','Balance','Uniformity','Clean.Cup',\n",
    "                          'Sweetness','Cupper.Points']]\n",
    "\n",
    "y_train = df_train['coffee_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c3832",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f22194",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_val.loc[:,['Aroma', 'Flavor', 'Aftertaste','Acidity'\n",
    "                          ,'Body','Balance','Uniformity','Clean.Cup',\n",
    "                          'Sweetness','Cupper.Points']]\n",
    "y = df_val['coffee_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ba2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "for k, v in counter.items():\n",
    "    dist = v / len(y) * 100 \n",
    "    print(f\"Class= {k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c64098",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16,8))\n",
    "plt.bar(counter.keys(),counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7405a70",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state = 0)\n",
    "x, y = oversample.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "for k, v in counter.items():\n",
    "    dist = v / len(y) * 100 \n",
    "    print(f\"Class= {k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f653491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16,8))\n",
    "plt.bar(counter.keys(),counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a153f",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae4850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression(C=0.5)\n",
    "scores2 = []\n",
    "pre_score2 = []\n",
    "recall_score2 = []\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "    train_x, val_x = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_x, train_y = oversample.fit_resample(train_x, train_y)\n",
    "    lm.fit(train_x, train_y)\n",
    "    y_pred =lm.predict(val_x)\n",
    "    scores2.append((metrics.f1_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    pre_score2.append((metrics.precision_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    recall_score2.append((metrics.recall_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    \n",
    "print(\"LogisticRegression score: \\t\")\n",
    "print(sum(scores2) / len(scores2))\n",
    "print(\"----------------\")\n",
    "conf_mat2 = confusion_matrix(val_y, y_pred)\n",
    "print(\"LogisticRegression confusion matrix: \\n\",conf_mat2)\n",
    "print(\"----------------\")\n",
    "print(\"LogisticRegression precision score\")\n",
    "print(sum(pre_score2) / len(pre_score2))\n",
    "print(\"----------------\")\n",
    "print(\"LogisticRegression recall_score\")\n",
    "print(sum(recall_score2) / len(recall_score2))\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ae257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =lm.predict(x)\n",
    "print(\"LogisticRegression f1 score: \\t\")\n",
    "print(metrics.f1_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"LogisticRegression precision score\")\n",
    "print(metrics.precision_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"LogisticRegression recall_score\")\n",
    "print((metrics.recall_score(y, y_pred_test, pos_label='3',average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bd83f",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores3 = []\n",
    "pre_score3 = []\n",
    "recall_scor3 = []\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "\n",
    "    train_x, val_x = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    \n",
    "    \n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_x, train_y = oversample.fit_resample(train_x, train_y)\n",
    "    knn.fit(train_x, train_y)\n",
    "    y_pred =knn.predict(val_x)\n",
    "    scores3.append(metrics.f1_score(val_y, y_pred, pos_label='3',average='micro'))\n",
    "    pre_score3.append(metrics.precision_score(val_y, y_pred, pos_label='3',average='micro'))\n",
    "    recall_scor3.append(metrics.recall_score(val_y, y_pred, pos_label='3',average='micro'))\n",
    "\n",
    "print(\"kNN f1 score: \\t\")\n",
    "print(sum(scores3) / len(scores3))\n",
    "print(\"----------------\")\n",
    "conf_mat3 = confusion_matrix(val_y, y_pred)\n",
    "print(\"kNN confusion matrix: \\n\",conf_mat3)\n",
    "print(\"----------------\")\n",
    "print(\"KNN precision score\")\n",
    "print(sum(pre_score3) / len(pre_score3))\n",
    "print(\"----------------\")\n",
    "print(\"KNN recall_score\")\n",
    "print(sum(recall_scor3) / len(recall_scor3))\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(model1, x, y, cv=5, n_jobs=-1, scoring='f1_macro')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d249d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a260e8",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "de =  DecisionTreeClassifier(max_depth=4)\n",
    "scores1 = []\n",
    "pre_score1 = []\n",
    "recall_score1 = []\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "    train_X, val_X = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_X, train_y = oversample.fit_resample(train_X, train_y)\n",
    "    de.fit(train_X, train_y)\n",
    "    y_pred =de.predict(val_X)\n",
    "    scores1.append((metrics.f1_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    pre_score1.append((metrics.precision_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    recall_score1.append((metrics.recall_score(val_y, y_pred, pos_label='3',average='micro'))) \n",
    "    \n",
    "print(\"Decision Tree score: \\t\")\n",
    "print(sum(scores1) / len(scores1))\n",
    "print(\"----------------\")\n",
    "conf_mat1 = confusion_matrix(val_y, y_pred)\n",
    "print(\"Decision Tree confusion matrix: \\n\",conf_mat1)\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree precision score\")\n",
    "print(sum(pre_score1) / len(pre_score1))\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree recall_score\")\n",
    "print(sum(recall_score1) / len(recall_score1))\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =de.predict(x)\n",
    "print(\"Decision Tree f1 score: \\t\")\n",
    "print(metrics.f1_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree precision score\")\n",
    "print(metrics.precision_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree recall_score\")\n",
    "print((metrics.recall_score(y, y_pred_test, pos_label='3',average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32bceb",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm =  RandomForestClassifier(n_estimators=100)\n",
    "scores = []\n",
    "pre_score = []\n",
    "recall_score = []\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "    train_X, val_X = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_X, train_y = oversample.fit_resample(train_X, train_y)\n",
    "    rm.fit(train_X, train_y)\n",
    "    y_pred =rm.predict(val_X)\n",
    "    scores.append((metrics.f1_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    pre_score.append((metrics.precision_score(val_y, y_pred, pos_label='3',average='micro')))\n",
    "    recall_score.append((metrics.recall_score(val_y, y_pred, pos_label='3',average='micro'))) \n",
    "    \n",
    "print(\"Decision Tree F1: \\t\")\n",
    "print(sum(scores) / len(scores))\n",
    "print(\"----------------\")\n",
    "conf_mat = confusion_matrix(val_y, y_pred)\n",
    "print(\"Decision Tree confusion matrix: \\n\",conf_mat)\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree precision score\")\n",
    "print(sum(pre_score) / len(pre_score))\n",
    "print(\"----------------\")\n",
    "print(\"Decision Tree recall_score\")\n",
    "print(sum(recall_score) / len(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =rm.predict(x)\n",
    "print(\"Random Forest f1 score: \\t\")\n",
    "print(metrics.f1_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Random Forest precision score\")\n",
    "print(metrics.precision_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Random Forest recall_score\")\n",
    "print((metrics.recall_score(y, y_pred_test, pos_label='3',average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6e577",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 765\n",
    "score_vot = []\n",
    "pre_score_vot = []\n",
    "recall_score_vot = []\n",
    "log_clf = KNeighborsClassifier()\n",
    "rnd_clf = RandomForestClassifier(random_state=seed)\n",
    "dt_clf = DecisionTreeClassifier(random_state=seed)\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf),('df', dt_clf),('rf',rnd_clf)], voting='hard')\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "    train_X, val_X = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_X, train_y = oversample.fit_resample(train_X, train_y)\n",
    "    voting_clf.fit(train_X, train_y)\n",
    "    y_pred_tv_vclf =voting_clf.predict(val_X)\n",
    "    score_vot.append(metrics.f1_score(val_y, y_pred_tv_vclf, pos_label='3',average='micro'))\n",
    "    pre_score_vot.append(metrics.precision_score(val_y, y_pred_tv_vclf, pos_label='3',average='micro'))\n",
    "    recall_score_vot.append(metrics.recall_score(val_y, y_pred_tv_vclf, pos_label='3',average='micro'))\n",
    "    \n",
    "print(\"voting F1: \\t\")\n",
    "print(sum(score_vot) / len(score_vot))\n",
    "print(\"----------------\")\n",
    "print(\"voting precision score\")\n",
    "print(sum(pre_score_vot) / len(pre_score_vot))\n",
    "print(\"----------------\")\n",
    "print(\"votingrecall_score\")\n",
    "print(sum(recall_score_vot) / len(recall_score_vot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =voting_clf.predict(x)\n",
    "print(\"voting f1 score: \\t\")\n",
    "print(metrics.f1_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"voting precision score\")\n",
    "print(metrics.precision_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"voting recall_score\")\n",
    "print((metrics.recall_score(y, y_pred_test, pos_label='3',average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34cc84",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15064383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bg = BaggingClassifier(RandomForestClassifier(), n_estimators=10, max_samples=0.5, bootstrap=True,n_jobs=-1)\n",
    "scores_b = []\n",
    "pre_score_b = []\n",
    "recall_score_b = []\n",
    "kfold = KFold(n_splits=5)\n",
    "for train_ix, val_ix in kfold.split(x, y):\n",
    "    train_X, val_X = x.iloc[train_ix], x.iloc[val_ix]\n",
    "    train_y, val_y = y.iloc[train_ix], y.iloc[val_ix]\n",
    "    oversample = SMOTE(random_state = 0)\n",
    "    train_X, train_y = oversample.fit_resample(train_X, train_y)\n",
    "    bg.fit(train_X, train_y)\n",
    "    y_pred_tv_bg1 =bg.predict(val_X)\n",
    "    scores_b.append(metrics.recall_score(val_y, y_pred_tv_bg1, pos_label='3',average='micro'))\n",
    "    pre_score_b.append(metrics.precision_score(val_y, y_pred_tv_bg1, pos_label='3',average='micro'))\n",
    "    recall_score_b.append(metrics.recall_score(val_y, y_pred_tv_bg1, pos_label='3',average='micro'))\n",
    "print(\"Bagging F1: \\t\")\n",
    "print(sum(scores_b) / len(scores_b))\n",
    "print(\"Bagging precision score\")\n",
    "print(sum(pre_score_b) / len(pre_score_b))\n",
    "print(\"----------------\")\n",
    "print(\"Bagging recall_score\")\n",
    "print(sum(recall_score_b) / len(recall_score_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =bg.predict(x)\n",
    "print(\"Bagging f1 score: \\t\")\n",
    "print(metrics.f1_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Bagging precision score\")\n",
    "print(metrics.precision_score(y, y_pred_test, pos_label='3',average='micro'))\n",
    "print(\"----------------\")\n",
    "print(\"Bagging recall_score\")\n",
    "print((metrics.recall_score(y, y_pred_test, pos_label='3',average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d58544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e13e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
